# 使用神经网络解决逆问题

## 目录
- 问题表述
- 不可压缩流体的控制
- 数据生成
- 监督初始化
- 使用可微分物理进行 CFE 预训练
- 使用可微分物理进行端到端训练
- 后续步骤

逆问题涵盖了科学中一大类实际应用。通常，这里的目标不是直接计算物理场（如未来某个时间的速度）（这是正向求解的典型场景），而是更通用地计算模型方程中的一个或多个参数，以满足某些约束。一个非常常见的目标是为某个参数找到最优设置，给定一些约束。例如，这可能是平流-扩散模型的全局扩散常数，以便尽可能准确地拟合测量数据。逆问题在任何通过观察调整模型参数或重建初始条件（例如，用于粒子图像测速（PIV））时都会遇到。更复杂的情况旨在计算边界几何形状以满足最优条件，例如，在流体流动中获得具有最小阻力的形状。

下面的一个关键方面是，我们的目标不是只解决逆问题的单个实例，而是希望使用深度学习来解决更大的逆问题集合。因此，与 **Burgers Optimization with a PINN** 的物理信息示例或 **Differentiable Fluid Simulations** 的可微分物理（DP）优化不同（在那里我们解决了特定逆问题实例的优化问题），我们现在旨在训练一个神经网络（NN），学习解决更大类别的逆问题，即整个解流形。尽管如此，我们当然需要依赖这些问题的一定程度的相似性，否则就没有什么可学习的（并且解流形中连续性的隐含假设就会崩溃）。

下面我们将运行一个非常具有挑战性的测试案例作为这些逆问题的代表：我们将旨在计算一个高维控制函数，该函数在不可压缩流体模拟的整个过程中施加力，以便为流体中被动平流的标记达到期望的目标状态。这意味着我们只有非常间接的约束要满足（序列末端的一个单一状态），并且有大量的自由度（控制力函数是一个时空函数，具有与流场本身相同的自由度）。

控制的长期性是使这成为一个艰难逆问题的方面之一：对物理系统状态的任何更改都可能导致后期发生巨大变化，因此控制器需要预测系统在受到影响时将如何行为。这意味着神经网络还需要学习底层物理如何演化和变化，而这正是 DP 训练中的梯度发挥作用的地方，引导学习任务找到能够达到目标的解决方案。

[警告：此代码现在是一个非常“经典”的代码，并且需要相当多的旧版 API，这些 API 在 colab 上不再受支持（最重要的是 Python3.6 与 TF1.14 和 phiflow 1.4.1）。因此，建议在本地 conda 环境中运行此示例，而不是在 colab 中。]

(

##### 原文核心意思

- **逆问题（Inverse Problems）**：不是直接算“未来会怎样”，而是反过来——**给定一些结果或观测，推回去找模型参数或初始条件**。

  - 例如：知道流体里某时刻的速度场，倒推出一开始的状态；
  - 或者，给定实验数据，调整扩散系数，让模型结果和实验对上。

- **挑战**：

  - 我们不只是解一个单一问题，而是希望用**神经网络学会一整类逆问题**。
  - 这意味着网络要能泛化，而不是只会解一个特例。

- **难点案例**：

  - 控制不可压缩流体模拟的整个过程，在流体里施加力（控制函数），
  - 目标：让烟雾标记物在最后时刻形成一个目标形状。
  - 难点在于：
    1. 我们只有终点约束（最后一帧的形状），
    2. 但控制量是“随时间变化的空间力场”（自由度巨大）。
  - 小小的干预，可能会让后面几十步完全跑偏，所以 NN 必须理解物理演化过程。

- **DP 梯度的作用**：

  - 传统神经网络很难直接学到这种“长时间控制”问题。

  - 但是如果 PDE 求解器是可微的（DP），反向传播会告诉 NN：

    > 你在第 3 步施加的力，最终怎么影响了第 50 步的烟雾形状。

  - 这样 NN 就能学会正确地控制系统。

)

## 问题表述

使用**模型与方程**中的符号，这给出了最小化问题：

$$
\arg \min_{\theta} \sum_{m} \sum_{i} (f(x_{m,i}; \theta) - y^*_{m,i})^2,
$$

其中 $y^*_{m,i}$ 表示标记场目标状态的样本，$x_{m,i}$ 表示模拟的标记密度状态。和之前一样，索引 $i$ 在不同的空间位置（通常是所有网格单元）对我们的解进行采样，而索引 $m$ 在这里表示大量不同的目标状态。

我们的目标是训练两个网络 $OP$ 和 $CFE$，其权重分别为 $\theta_{OP}$ 和 $\theta_{CFE}$，使得一个序列

$$
u_n, d_n = P(CFE( P(CFE(\cdots P(CFE(u_0, d_0, d_{OP}))\cdots)))) = (P \circ CFE)^n (u_0, d_0, d_{OP}).
$$

最小化上述损失。网络 $OP$ 是一个预测器，确定 $CFE$ 的动作应瞄准的状态，即，它进行长期规划以确定动作。给定目标 $d^*$，它计算 $d_{OP} = OP(d, d^*) = f_{OP}(d, d^*; \theta_{OP})$。$CFE$ 通过计算 $u + f_{CFE}(u, d, f_{OP}(d, d^*; \theta_{OP}); \theta_{CFE})$ 对速度场进行加性作用，其中我们使用了 $f_{OP}$ 和 $f_{CFE}$ 来分别表示 $OP$ 和 $CFE$ 的 NN 表示，而 $d^*$ 表示目标密度状态。$\theta_{OP}$ 和 $\theta_{CFE}$ 表示相应的网络权重。

对于这个问题，模型 PDE 包含二维不可压缩 Navier-Stokes 方程的离散化版本，用于速度 $u$：

$$
\begin{aligned}
\frac{\partial u_x}{\partial t} + u \cdot \nabla u_x &= -\frac{1}{\rho} \nabla p \\
\frac{\partial u_y}{\partial t} + u \cdot \nabla u_y &= -\frac{1}{\rho} \nabla p \\
\text{s.t.} \quad \nabla \cdot u &= 0,
\end{aligned}
$$

没有显式粘度，并且有一个用于标记密度 $d$ 的附加输运方程，由 $\frac{\partial d}{\partial t} + u \cdot \nabla d = 0$ 给出。

总结一下，我们有一个给出方向的预测器 $OP$，一个对物理模型 $P$ 施加力的执行器 $CFE$。它们都需要协同工作，以便在模拟 $n$ 次迭代后达到给定目标。从这种表述可以看出，这不是一个简单的逆问题，特别是因为所有三个函数都是非线性的。这正是 DP 方法的梯度如此重要的原因。（上述观点也表明强化学习是一个潜在的选择。在**使用强化学习控制 Burgers 方程**中，我们将把 DP 与这些替代方案进行比较。）

(

我们希望控制一个**流体模拟**，让里面的“烟雾/标记物”在最后某个时间形成我们想要的目标形状。

- 模拟器 $P$：物理求解器（Navier-Stokes 方程 + 被动烟雾输运）
- OP 网络：像个“参谋”，告诉系统应该往哪个方向努力（目标参考状态）。
- CFE 网络：像个“执行器”，它接收 OP 的建议后，具体算出要对流体施加什么力（作用在速度场 $u$ 上）。

整个过程是：初始速度 $u_0$ 和烟雾 $d_0$ → 经过 **CFE 施加力** → PDE $P$ 演化 → 下一步的状态，再进入下一次循环。经过 $n$ 步迭代，得到的最终烟雾状态 $d_n$ 应该尽量接近我们给定的目标 $d^*$。

)

## 不可压缩流体的控制

接下来的部分将引导您完成从数据生成到使用 $\Phi_{\text{Flow}}$ 进行网络训练的所有必要步骤。由于控制问题的复杂性，我们将从网络的监督初始化开始，然后切换到使用 DP 进行更精确的端到端训练。（注意：此示例使用 $\Phi_{\text{Flow}}$ 的旧版本 1.4.1。）

下面的代码复制了来自 *Learning to Control PDEs with Differentiable Physics* [HKT19] 的逆问题示例（形状转换实验），更多细节可以在论文附录的 D.2 节中找到。

首先我们需要加载 phiflow 并 checkout PDE-Control git 存储库，该存储库还包含一些带有初始形状的 numpy 数组。

```python
!pip install --quiet phiflow==1.4.1
import matplotlib.pyplot as plt
from phi.flow import *
if not os.path.isdir('PDE-Control'):
    print("Cloning PDE-Control repo, this can take a moment")
    os.system("git clone --recursive https://github.com/holl-/PDE-Control.git")

# 现在我们可以加载必要的 phiflow 库和辅助函数
import sys; sys.path.append('PDE-Control/src')
from shape_utils import load_shapes, distribute_random_shape
from control.pde.incompressible_flow import IncompressibleFluidPDE
from control.control_training import ControlTraining
from control.sequences import StaggeredSequence, RefinedSequence
```

## 数据生成

在开始训练之前，我们必须生成一个数据集来训练，即一组真实时间序列 $u^*$。由于下面训练的复杂性，我们将采用分阶段的方法，预训练一个监督网络作为粗略初始化，然后对其进行细化，以学习看得越来越远的控制。（这将通过训练处理越来越长序列的专门 NN 来实现。）

首先，让我们设置数据生成步骤的域和基本参数。

最后一行中的 `shape_library` 包含十个不同的形状，我们将使用它们在随机位置初始化标记密度。

这些形状看起来像这样：

```python
domain = Domain([64, 64])  # 1D 网格分辨率和物理大小
step_count = 16            # 要执行多少个求解器步骤
dt = 1.0                   # 每个求解器步骤的时间增量
example_count = 1000
batch_size = 100
data_path = 'shape-transitions'
pretrain_data_path = 'moving-squares'
shape_library = load_shapes('PDE-Control/notebooks/shapes')

import pylab
pylab.subplots(1, len(shape_library), figsize=(17, 5))
for t in range(len(shape_library)):
    pylab.subplot(1, len(shape_library), t+1)
    pylab.imshow(shape_library[t], origin='lower')
```

以下单元格使用这些形状创建我们想要训练网络的数据集。每个示例由一个开始帧和目标（结束）帧组成，这些帧通过将 `shape_library` 中的随机形状放置在域内的某个位置生成。

由于此数据集不包含任何中间帧，因此不允许进行监督预训练。这是因为预训练 CFE 网络需要两个连续的帧，而预训练 $OP_n$ 网络需要距离为 $n/2$ 的三个帧。

相反，我们创建第二个包含这些中间帧的数据集。这不需要非常接近实际数据集，因为它仅用于通过预训练初始化网络。在这里，我们线性地在域内移动一个矩形。

```python
# 为形状转换创建主数据集（只有开始和目标状态）
for scene in Scene.list(data_path): scene.remove()
for _ in range(example_count // batch_size):
    scene = Scene.create(data_path, count=batch_size, copy_calling_script=False)
    print(scene)
    start = distribute_random_shape(domain.resolution, batch_size, shape_library)
    end__ = distribute_random_shape(domain.resolution, batch_size, shape_library)
    [scene.write_sim_frame([start], ['density'], frame=f) for f in range(step_count)] # 开始状态写多次（占位）
    scene.write_sim_frame([end__], ['density'], frame=step_count) # 目标状态写在最后

# 为预训练创建辅助数据集（移动方块，包含中间状态）
for scene in Scene.list(pretrain_data_path): scene.remove()
for scene_index in range(example_count // batch_size):
    scene = Scene.create(pretrain_data_path, count=batch_size, copy_calling_script=False)
    print(scene)
    pos0 = np.random.randint(10, 56, (batch_size, 2))  # 起始位置
    pose = np.random.randint(10, 56, (batch_size, 2))  # 结束位置
    size = np.random.randint(6, 10, (batch_size, 2))
    for frame in range(step_count+1):
        time = frame / float(step_count + 1)
        pos = np.round(pos0 * (1 - time) + pose * time).astype(np.int)
        density = AABox(lower=pos-size//2, upper=pos-size//2+size).value_at(domain.center_points()) # 创建方块
        scene.write_sim_frame([density], ['density'], frame=frame)
```

## 监督初始化

首先我们将 1000 个数据样本分为 100 个测试样本、100 个验证样本和 800 个训练样本。

```python
test_range = range(100)
val_range = range(100, 200)
train_range = range(200, 1000)
```

以下单元格训练所有的 $OP_n \quad \forall n \in \{2, 4, 8, 16\}$。这里的 $n$ 表示网络预测目标的时间步数。为了覆盖更长的时间范围，我们在这里使用 2 的幂来分层划分应控制物理系统的时间间隔。

使用 `ControlTraining` 类来设置相应的优化问题。监督初始化的损失定义为中间帧速度的观测损失：

$$
L^{\text{sup}}_o = \| OP(d_{t_i}, d_{t_j}) - d^*_{(t_i+t_j)/2} \|^2.
$$

因此，不需要模拟序列 (`sequence_class=None`)，并且在帧 $n/2$ 处需要观测损失 (`obs_loss_frames=[n // 2]`)。预训练的网络检查点存储在 `supervised_checkpoints` 中。

注意：下一个单元格将运行一段时间。PDE-Control git 仓库附带了一组预训练网络。因此，如果您想专注于评估，可以跳过训练，并通过注释掉训练单元格并取消注释下面的加载单元格来加载预训练网络。

```python
supervised_checkpoints = {}
for n in [2, 4, 8, 16]:
    app = ControlTraining(n, IncompressibleFluidPDE(domain, dt),
                         datapath=pretrain_data_path, val_range=val_range, train_range=train_range,
                         obs_loss_frames=[n//2], trainable_networks=['OP%d' % n],
                         sequence_class=None).prepare()
    for i in range(1000):
        app.progress()  # 为一个批次运行优化
    supervised_checkpoints['OP%d' % n] = app.save_model()

# supervised_checkpoints = {'OP%d' % n: 'PDE-Control/networks/shapes/supervised/OP%d_1000' % n for n in [2,4,8,16]} # 取消注释以加载预训练的
```

这结束了 OP 网络的预训练。这些网络使得至少可以对运动进行粗略的规划，这将在下面通过端到端训练进行细化。然而，在此之前，我们将初始化 $CFE$ 网络，以便我们可以执行动作，即对模拟施加力。这与 $OP$ 网络完全分离。

## 使用可微分物理进行 CFE 预训练

为了预训练 $CFE$ 网络，我们设置了一个具有单个可微分求解器步骤的模拟。

以下单元格从头开始训练 $CFE$ 网络。如果您有预训练的网络，可以通过运行后面的单元格跳过训练并加载检查点。

请注意，我们实际上没有为训练设置模拟，因为网络只推断状态对之间的力。

```python
app = ControlTraining(1, IncompressibleFluidPDE(domain, dt),
                     datapath=pretrain_data_path, val_range=val_range, train_range=train_range,
                     obs_loss_frames=[1], trainable_networks=['CFE']).prepare()
for i in range(1000):
    app.progress()  # 为一个批次运行优化
supervised_checkpoints['CFE'] = app.save_model()

# supervised_checkpoints['CFE'] = 'PDE-Control/networks/shapes/CFE/CFE_2000' # 取消注释以加载预训练的
```

## 使用可微分物理进行端到端训练

现在两种网络类型的初始版本都存在了，我们可以启动手头设置中最重要的步骤：通过可微分流体求解器对两个网络进行耦合的端到端训练。虽然预训练阶段依赖于监督训练，但下一步将为控制带来显著提高的质量。

为了在 phiflow 中使用可微分物理损失启动 $CFE$ 和所有 $OP_n$ 网络的端到端训练，我们使用交错执行方案创建一个新的 `ControlTraining` 实例。

以下单元格构建了具有 `step_count` 个求解器步骤的计算图，而不初始化网络权重。

```python
staggered_app = ControlTraining(step_count, IncompressibleFluidPDE(domain, dt),
                               datapath=data_path, val_range=val_range, train_range=train_range,
                               obs_loss_frames=[step_count], trainable_networks=['CFE', 'OP2', 'OP4', 'OP8', 'OP16'],
                               sequence_class=StaggeredSequence, learning_rate=5e-4).prepare()
```

下一个单元格使用监督检查点初始化网络，然后联合训练所有网络。您可以增加优化步骤的数量或多次执行下一个单元格以进一步提高性能。

注意：下一个单元格将运行一段时间。或者，您可以跳过此单元格，并使用下面单元格中的代码加载预训练网络。

```python
staggered_app.load_checkpoints(supervised_checkpoints)
for i in range(1000):
    staggered_app.progress()  # 运行交错优化一个批次
staggered_checkpoint = staggered_app.save_model()

# staggered_checkpoint = {net: 'PDE-Control/networks/shapes/staggered/all_53750' for net in ['CFE', 'OP2', 'OP4', 'OP8', 'OP16']} # 取消注释以加载预训练的
# staggered_app.load_checkpoints(staggered_checkpoint)
```

现在网络已经训练好，我们可以从测试集中推断一些轨迹。（这对应于原始论文的图 5b 和 18b。）

以下单元格获取前一百个配置，即由 `test_range` 定义的我们的测试集，并让网络推断相应逆问题的解。

通过下面的索引列表 `batches`，您可以选择显示一些解。每一行显示一个时间序列，从初始条件开始，并使用 NN 控制力演化模拟 16 个时间步。最后一步，$t=16$，应与最右边图像中显示的目标匹配。

```python
states = staggered_app.infer_all_frames(test_range)

batches = [0, 1, 2]
pylab.subplots(len(batches), 10, sharey='row', sharex='col', figsize=(14, 6))
pylab.tight_layout(w_pad=0)
# 解
for i, batch in enumerate(batches):
    for t in range(9): # 显示 0, 2, 4, ..., 16 步
        pylab.subplot(len(batches), 10, t + 1 + i * 10)
        pylab.title('t=%d' % (t * 2))
        pylab.imshow(states[t * 2].density.data[batch, ..., 0], origin='lower') # 显示密度场
# 添加目标
testset = BatchReader(Dataset.load(staggered_app.data_path, test_range), staggered_app.app)
for i, batch in enumerate(batches):
    pylab.subplot(len(batches), 10, i * 10 + 10)
    pylab.title('target')
    pylab.imshow(testset[1][i, ..., 0], origin='lower') # testset[1] 包含目标状态
```

正如您在最右边两列中看到的那样，网络在解决这些逆问题方面做得非常好：流体标记被推送到正确的位置并以正确的方式变形以匹配目标。

这里看起来相当简单的事情实际上对神经网络来说是一项棘手的任务：它需要在 16 个时间积分步骤的过程中指导完整的 2D Navier-Stokes 模拟。因此，如果施加的力略有偏差或不连贯，流体可能会开始旋转并混乱地运动。然而，网络已经学会了将运动保持在一起，并引导标记密度到达目标位置。

接下来，我们通过比较最终密度配置相对于初始密度的平均绝对误差来量化实现的错误率。使用上面的标准训练设置，下一个单元格应该给出大约 5-6% 的相对残差误差。反之，这意味着大约 94% 的标记密度最终出现在正确的位置！

```python
errors = []
for batch in range(len(test_range)): # 遍历测试集的所有批次
    initial = np.mean(np.abs(states[0].density.data[batch, ..., 0] - testset[1][batch, ..., 0])) # 初始误差
    solution = np.mean(np.abs(states[16].density.data[batch, ..., 0] - testset[1][batch, ..., 0])) # 最终误差
    errors.append(solution / initial) # 相对误差
print("Relative MAE: " + format(np.mean(errors)))
# 输出: Relative MAE: 0.05450168251991272
```

## 后续步骤

对于此源代码的进一步实验，您可以，例如：

*   更改 `test_range` 索引以查看不同的示例，或通过使用新形状作为目标来测试训练好的控制器网络的泛化能力。
*   尝试使用 `RefinedSequence`（而不是 `StaggeredSequence`）通过预测细化方案进行训练。这将产生进一步改进的控制和减少的密度误差。