# 基于物理信息神经网络（PINN）的 Burgers 方程优化

## 目录
- 问题表述
- 准备工作
- 损失函数与训练
- 结果评估
- 后续步骤

为了说明变体 2 中物理信息损失函数的工作原理，我们考虑一个作为逆向问题示例的重构任务。我们将使用 Burgers 方程作为一维中的一个简单 yet 非线性的方程，我们在时间 `t = 0.5` 处对其有一系列观测值。解应满足 Burgers 方程的残差公式并与观测值匹配。此外，让我们在我们的计算域边界施加狄利克雷边界条件 `u = 0`，并在时间区间 `t ∈ [0, 1]` 内定义解。

**Burgers方程** 是一个著名的非线性方程，经常用作流体动力学、气体动力学等问题的简化模型。它是由对流项和扩散项构成的偏微分方程，具有如下形式：
$$
\frac{\partial u}{\partial t} + u \frac{\partial u}{\partial x} = \nu \frac{\partial^2 u}{\partial x^2}
$$
其中，$u(x, t)$ 是速度（或浓度、温度等物理量），$\nu$ 是粘度（或扩散系数），$t$ 是时间，$x$ 是空间坐标。

在这个问题中，目标是重构在时间 $t = 0.5$ 时的解。为了达到这个目标，借助神经网络的灵活性来逼近解。



请注意，与之前的前向模拟示例类似，我们将使用 128 个点 (`n = 128`) 对解进行采样，但现在是通过 NN 进行离散化。因此我们也可以在不显式选择插值基函数的情况下对中间的点进行采样。通过 NN 进行的离散化现在在内部决定了如何安排其激活函数作为基函数来利用其自由度。因此我们对重构没有直接控制。[在 colab 中运行]

## 问题表述

根据“模型与方程”及前一节的符号表示，这个重构问题意味着我们要求解：

$$
\arg \min_{\theta} \sum_i (f(x_i; \theta) - y^*_i)^2 + R(x_i)
$$

其中现在 `x_i` 表示一个时空点 `x_i = [p_i, t_i]`，参考解是 `y^*_i = y^*(x_i)`，索引 `i` 表示我们数据集的不同采样点。`f` 和 `y^*` 都表示在不同时空位置处 `u` 的解，并且因为我们处理的是 1D 速度场，`f, y^*: \mathbb{R}^2 \rightarrow \mathbb{R}`。在此示例中，`y^*` 表示 Burgers 方程的一个参考，它应尽可能在所有选定的时空点 `x_i = [p_i, t_i]` 上逼近 `u`。

虽然上面的第一项是“监督”数据项，但第二项表示残差函数 `R`。它收集 `f` 及其导数的额外评估值以构建 `P` 的残差。这种方法——使用神经网络的导数来计算 PDE 残差——通常被称为物理信息方法，产生一个物理信息神经网络 (PINN) [RPK19] 来表示逆向重构问题的解。

因此，在上面的公式中，`R` 应该简单地收敛到零。为简单起见，我们在目标函数中省略了缩放因子。请注意，实际上，我们这里只处理 `u` 的单个解的各个点样本。

### **第一项：$\sum_i (f(x_i; \theta) - y_i^*)^2$**

- 这部分是标准的 **监督学习损失项**，即网络输出与实际观测（参考解）之间的误差平方和。目标是让神经网络的预测 $f(x_i; \theta)$ 尽量接近参考解 $y^*_i$，以便重构Burgers方程的解。

### 第二项：$R(x_i)$

- 这是一个 **残差函数**，用于强制神经网络的解符合Burgers方程的物理约束。Burgers方程是一个偏微分方程（PDE），通过残差项 $R(x_i)$ 可以对每个时空点 $x_i$ 计算出该点是否满足Burgers方程。
- 换句话说，残差项 $R(x_i)$ 用来衡量神经网络在预测解时是否遵循方程的物理规律。具体来说，它可能包含神经网络解的导数（如时间导数和空间导数），并且要求它们与Burgers方程中的导数项一致。该项的最终目的是将PDE的物理约束嵌入到损失函数中，确保神经网络的解不仅仅在数据点上拟合准确，而且在整个时空域内符合方程。

## 准备工作

这个笔记本有点旧，因此需要较旧的 tensorflow 版本。下一个单元格安装/降级 TF 到一个兼容的版本。由于 pip 依赖关系，这可能会在 colab 上导致“错误”，您可以安全地忽略这些错误：

```python
!pip3 install --upgrade --quiet tensorflow==2.15.0 tensorflow-probability==0.23.0
!pip install --upgrade --quiet git+https://github.com/thunil/PhiFlow.git
```

接下来，我们将在下面加载 phiflow（使用来自自定义存储库的旧版本 1.5.1）。我们将将其与 tensorflow 后端一起使用，并初始化随机采样。

我们在这里导入 phiflow，但不会像在“使用 phiflow 对 Burgers 方程进行简单前向模拟”中那样用它来求解 PDE。相反，我们将使用 NN 的导数（如前一节所述）来建立训练用的损失公式。

python

```
from phi.tf.flow import *
import numpy as np
#rnd = TF_BACKEND # for phiflow: sample different points in the domain each iteration
rnd = math.choose_backend(1) # use same random points for all iterations
```

接下来，我们建立一个具有 8 个全连接层、每层 20 个单元并使用 tanh 激活函数的简单 NN。

我们还将定义 `boundary_tx` 函数，该函数提供解的约束数组（在此示例中全部在 `t = 0.5`），以及 `open_boundary` 函数，该函数存储 `u` 为 0 的约束。

最重要的是，我们现在还可以构建我们想要最小化的残差损失函数 `f`，以指导 NN 获取我们模型方程的解。正如顶部的方程所示，我们需要关于 `t` 和 `x` 的导数，以及 `x` 的二阶导数。下面函数 `f` 的前三行正是做这个。

之后，我们简单地组合这些导数来形成 Burgers 方程。这里我们利用了 phiflow 的梯度函数：

python

```python
# 定义神经网络
def network(x, t):
    """ 具有8个隐藏层和总共3021个参数的密集神经网络。
    参数将只分配一次（自动重用）。
    """
    y = math.stack([x, t], axis=-1)  # 将输入的 x 和 t 合并为一个时空点的输入
    for i in range(8):  # 8个隐藏层
        y = tf.layers.dense(y, 20, activation=tf.math.tanh, name='layer%d' % i, reuse=tf.AUTO_REUSE)
    return tf.layers.dense(y, 1, activation=None, name='layer_out', reuse=tf.AUTO_REUSE)

# 生成边界条件的时空点
def boundary_tx(N):
    """ 生成 N 个时空点的边界条件数据。 """
    x = np.linspace(-1, 1, 128)
    u = np.asarray([0.008612174447657694, 0.02584669669548606, 0.04313635726640778, ...])  # 假设有128个值
    t = np.asarray(np.ones_like(x)) * 0.5  # 时间固定为0.5
    perm = np.random.permutation(128)
    return (x[perm])[0:N], (t[perm])[0:N], (u[perm])[0:N]

# 替代方案，生成 t=0 时的初始状态
def _ALT_t0(N): 
    """ 在 t=0 时施加原始初始状态。 """
    x = np.random.uniform(-1, 1, N)  # 随机生成空间坐标 x
    t = np.zeros_like(x)  # 时间坐标 t 设置为 0
    u = - np.sin(np.pi * x)  # 初始条件 u = -sin(pi * x)
    return x, t, u

# 边界条件：开放边界（x = ±1）
def open_boundary(N):
    """ 生成开放边界条件的数据。 """
    t = np.random.uniform(0, 1, N)  # 随机生成时间坐标 t
    x = np.concatenate([np.zeros([N // 2]) + 1, np.zeros([N // 2]) - 1], axis=0)  # x = ±1
    u = np.zeros([N])  # 边界条件下的解 u = 0
    return x, t, u

# 计算 Burgers 方程的物理残差
def f(u, x, t):
    """ 基于物理的Burgers方程损失函数 """
    u_t = gradients(u, t)  # u 关于时间 t 的导数
    u_x = gradients(u, x)  # u 关于空间 x 的一阶导数
    u_xx = gradients(u_x, x)  # u 关于空间 x 的二阶导数
    return u_t + u * u_x - (0.01 / np.pi) * u_xx  # Burgers 方程残差

# 计算导数（时间或空间上的）
def gradients(u, var):
    """ 计算 u 对 var（时间 t 或空间 x）的一阶导数 """
    return tf.gradients(u, var)[0]

# 示例：使用神经网络和物理信息损失函数解决 Burgers 方程
def solve_burgers(N):
    # 生成时空点数据
    x, t, u = boundary_tx(N)  # 或者使用 _ALT_t0(N) 或 open_boundary(N)

    # 转换为 TensorFlow 的张量
    x = tf.convert_to_tensor(x, dtype=tf.float32)
    t = tf.convert_to_tensor(t, dtype=tf.float32)
    u = tf.convert_to_tensor(u, dtype=tf.float32)

    # 计算网络输出
    u_pred = network(x, t)  # 预测的解

    # 计算物理信息损失（即Burgers方程残差）
    loss_phys = f(u_pred, x, t)

    # 计算数据拟合损失
    loss_data = tf.reduce_mean((u_pred - u)**2)  # 监督损失（数据拟合）

    # 总损失：数据损失 + 物理损失
    total_loss = loss_data + tf.reduce_mean(loss_phys)
    
    return total_loss

# 训练神经网络
def train_burgers(N, learning_rate=0.001, epochs=1000):
    """ 训练PINN来解决 Burgers 方程 """
    optimizer = tf.train.AdamOptimizer(learning_rate)
    for epoch in range(epochs):
        with tf.GradientTape() as tape:
            total_loss = solve_burgers(N)
        
        gradients = tape.gradient(total_loss, [var for var in tf.trainable_variables()])
        optimizer.apply_gradients(zip(gradients, [var for var in tf.trainable_variables()]))
        
        if epoch % 100 == 0:
            print(f'Epoch {epoch}, Loss: {total_loss.numpy()}')

```

接下来，让我们在内部域中设置采样点，以便我们可以将解与之前在 phiflow 中进行的前向模拟进行比较。

下一个单元格分配两个张量：`grid_x` 将覆盖我们域的大小，即 -1 到 1 的范围，具有 128 个单元，而 `grid_t` 将在时间区间 `[0, 1]` 内用 33 个时间戳进行采样。

在这个步骤中，我们正在为神经网络的训练过程进行准备，特别是设置适当的时空网格，并评估神经网络（NN）在这个网格上的初始状态。通过这些步骤，我们可以实现对Burgers方程解的逐步优化，最终将神经网络的输出与基于物理约束的PDE解进行比较。

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### 1. **设置时空网格 (`grid_x` 和 `grid_t`)**

- **作用**：我们需要在空间区间 $x \in [-1, 1]$ 和时间区间 $t \in [0, 1]$ 内设置适当的采样点。
- **代码解析**：

```
N = 128  # 在空间区间内使用128个采样点
grids_xt = np.meshgrid(np.linspace(-1, 1, N), np.linspace(0, 1, 33), indexing='ij')
grid_x, grid_t = [tf.convert_to_tensor(t, tf.float32) for t in grids_xt]
```

- `np.meshgrid` 用于创建一个网格，`grid_x` 将覆盖空间 $x$ 的范围（-1 到 1），并包含128个离散点。`grid_t` 将覆盖时间 $t$ 的范围（0到1），并包含33个时间戳。这两个张量分别代表空间和时间的采样点。

### 2. **创建4D张量（`grid_u`）**

- **作用**：将这两个空间和时间的网格输入到神经网络中，生成一个4D张量（`grid_u`），表示空间和时间上每个点的预测解 $u(x,t)$。
- **代码解析**：

```
grid_u = math.expand_dims(network(grid_x, grid_t))
```

- 在这里，`network(grid_x, grid_t)` 会将空间和时间的采样点传入之前定义的神经网络，得到一个预测的解。`math.expand_dims()` 会将输出张量扩展为一个具有批处理和通道维度的4D张量（即 $[1, 128, 33, 1]$），其中：
  - `1` 代表批处理维度（我们只使用一个样本）。
  - `128` 是空间维度。
  - `33` 是时间维度。
  - `1` 是输出通道（单一的解）。

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

最后一个 `math.expand_dims()` 调用只是添加了另一个批处理维度，以便生成的张量与后续示例兼容。

现在，`grid_u` 包含一个完整的图，用于在我们的 `[1, 128, 33, 1]` 位置评估我们的 NN，并在我们通过 `session.run` 运行它时在数组中返回结果。让我们试一下：我们可以初始化一个 TF 会话，评估 `grid_u` 并在图像中显示它，就像我们之前计算的 phiflow 解一样。

（注意，我们将使用“使用 phiflow 对 Burgers 方程进行简单前向模拟”中的 `show_state`。因此，x 轴不显示实际模拟时间，而是显示 32 个步骤，“放大”了 16 倍以使图像中随时间的变化更容易看到。）

python

```
N=128
grids_xt = np.meshgrid(np.linspace(-1, 1, N), np.linspace(0, 1, 33), indexing='ij')
grid_x, grid_t = [tf.convert_to_tensor(t, tf.float32) for t in grids_xt]
# 创建具有批处理和通道维度以及空间和时间的4D张量
# 在这种情况下得到 shape=(1, N, 33, 1)
grid_u = math.expand_dims(network(grid_x, grid_t))

import pylab as plt
print("Size of grid_u: "+format(grid_u.shape))
session = Session(None)
session.initialize_variables()

def show_state(a, title):
    for i in range(4): a = np.concatenate( [a,a] , axis=3)
    a = np.reshape( a, [a.shape[1],a.shape[2]*a.shape[3]] )
    fig, axes = plt.subplots(1, 1, figsize=(16, 5))
    im = axes.imshow(a, origin='upper', cmap='inferno')
    plt.colorbar(im) ; plt.xlabel('time'); plt.ylabel('x'); plt.title(title)

print("Randomly initialized network state:")
show_state(session.run(grid_u),"Uninitialized NN")
```

*(输出示例)*

text

```
Size of grid_u: (1, 128, 33, 1)
Randomly initialized network state:
```

*(此处应显示随机初始化NN的状态图像)*

这个可视化已经显示了随空间和时间的平滑过渡。到目前为止，这纯粹是我们正在采样的 NN 的随机初始化。所以到目前为止，它与我们基于 PDE 模型的解无关。

接下来的步骤将实际评估数据方面的约束（来自边界函数）和来自 `f` 的模型约束，以获取 PDE 的实际解。

## 损失函数与训练

作为学习过程的目标，我们现在可以将直接约束（即在 `t = 0.5` 处的解和狄利克雷边界条件）与来自 PDE 残差的损失结合起来。对于两个边界约束，下面我们将使用 100 个点，然后在内部区域用额外的 1000 个点对解进行采样。

直接约束通过 `network(x, t)[:, 0] - u` 进行评估，其中 x 和 t 是我们想要采样解的空间-时间位置，而 u 提供了相应的真实值。

对于物理损失点，我们没有真实解，但我们只会通过 NN 导数评估 PDE 残差，以查看解是否满足 PDE 模型。如果不满足，这会直接给我们一个误差，通过优化中的更新步骤来减少。相应的表达式是下面 `f(network(x, t)[:, 0], x, t)` 的形式。请注意，对于数据和物理项，`network()[:, 0]` 表达式不会从评估中删除任何数据，它们只是丢弃了 NN 返回的张量的最后一个大小为 1 的维度。

上面的代码只是初始化了损失的评估，我们还没有进行任何优化步骤，但我们终于处于开始进行优化的有利位置。

尽管方程简单，但收敛通常非常慢。迭代本身计算起来很快，但此设置需要大量迭代。为了将运行时间保持在合理范围内，我们在下面默认只进行 10k 次迭代 (`ITERS`)。您可以增加此值以获得更好的结果。

python

```
# Boundary loss
N_SAMPLE_POINTS_BND = 100
x_bc, t_bc, u_bc = [math.concat([v_t0, v_x], axis=0) for v_t0, v_x in zip(boundary_tx(N_SAMPLE_POINTS_BND//2), open_boundary(N_SAMPLE_POINTS_BND//2))]
x_bc, t_bc, u_bc = np.asarray(x_bc,dtype=np.float32), np.asarray(t_bc,dtype=np.float32), np.asarray(u_bc,dtype=np.float32)
#with app.model_scope():
loss_u = math.l2_loss(network(x_bc, t_bc)[:, 0] - u_bc) # 通过第一个维度归一化

# Physics loss inside of domain
N_SAMPLE_POINTS_INNER = 1000
x_ph, t_ph = tf.convert_to_tensor(rnd.random_uniform([N_SAMPLE_POINTS_INNER], -1, 1)), tf.convert_to_tensor(rnd.random_uniform([N_SAMPLE_POINTS_INNER], 0, 1))
loss_ph = math.l2_loss(f(network(x_ph, t_ph)[:, 0], x_ph, t_ph)) # 通过第一个维度归一化

# Combine
ph_factor = 1.
loss = loss_u + ph_factor * loss_ph # 允许我们控制物理损失的相对影响
optim = tf.train.GradientDescentOptimizer(learning_rate=0.02).minimize(loss)
#optim = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) # 替代方案，但通常更慢
```

由于训练使用了完善的构建块（密集层），在典型的笔记本上应该只需要大约 2 分钟，并且误差应该显著下降（大约从 0.2 降到约 0.03），网络似乎成功地收敛到一个解。

让我们显示网络的重构，通过在规则网格的中心评估网络，以便我们可以将解显示为图像。请注意，这实际上相当昂贵，因为我们必须为网格中的所有采样点运行具有几千个权重的整个网络。

乍一看，它看起来相当不错：与上面显示的随机初始化相比，发生了非常明显的变化：

python

```
session.initialize_variables()
import time
start = time.time()
ITERS = 10000
for optim_step in range(ITERS+1):
    _, loss_value = session.run([optim, loss])
    if optim_step<3 or optim_step%1000==0:
        print('Step %d, loss: %f' % (optim_step,loss_value))
        #show_state(grid_u) # 可选：每次迭代显示状态

end = time.time()
print("Runtime {:.2f}s".format(end-start))

show_state(session.run(grid_u),"After Training")
```

*(输出示例)*

text

```
Step 0, loss: 0.100037
Step 1, loss: 0.097836
Step 2, loss: 0.096151
Step 1000, loss: 0.054487
...
Step 10000, loss: 0.029434
Runtime 101.02s
```

*(此处应显示训练后的NN状态图像)*

## 结果评估

让我们更详细地比较解。下面是用于约束解的样本点（在时间步 16，`t = 1/2`）以灰色显示，与蓝色显示的重构解进行比较：

python

```
u = session.run(grid_u)
# 解在 t=1/2 处被施加，这在数组中是索引16
BC_TX = 16
uT = u[0,:,BC_TX,0]
fig = plt.figure().gca()
fig.plot(np.linspace(-1,1,len(uT)), uT, lw=2, color='blue', label="NN")
fig.scatter(x_bc[0:100], u_bc[0:100], color='gray', label="Reference") # 假设前100个点是 boundary_tx 的点
plt.title("Comparison at t=1/2")
plt.xlabel('x'); plt.ylabel('u'); plt.legend()
plt.show()
```

*(此处应显示t=0.5处的比较图)*

在域边界（狄利克雷边界条件 `u=0` 得到满足）看起来还不错，但中心（`x=0` 处）的激波表示得不好。

让我们检查一下在 `t=0` 处的初始状态重构得如何。这是问题中最有趣和最棘手的部分（其余部分基本上由模型方程和边界条件决定，给定初始状态）。

事实证明，初始状态的准确性实际上并不那么好：来自 PINN 的蓝色曲线与通过参考数据（灰色显示）的约束相差甚远…… 随着迭代次数的增加，解会变得更好，但对于这个相当简单的情况，它需要惊人的大量迭代。

特别是 `x = ±1/2` 处的最大值/最小值偏差很大，并且 `x = ±1` 处的边界条件未满足：解不为零。

我们拥有这个模拟的前向模拟器，因此我们可以使用网络的解来评估时间演化被重构得如何。这衡量了通过 PINN 损失的软约束捕获模型方程时间演化的效果。

python

```
# 在 t0 处的真实解
t0gt = np.asarray( [ [-math.sin(np.pi * x) * 1.] for x in np.linspace(-1,1,N)] )
velP0 = u[0,:,0,0] # NN 在 t=0 的解
fig = plt.figure().gca()
fig.plot(np.linspace(-1,1,len(velP0)), velP0, lw=2, color='blue', label="NN")
fig.plot(np.linspace(-1,1,len(t0gt)), t0gt, lw=2, color='gray', label="Reference")
plt.title("Comparison at t=0")
plt.xlabel('x'); plt.ylabel('u'); plt.legend()
plt.show()
```

*(此处应显示t=0处的比较图)*

下面的图表显示了蓝色显示的初始状态，以及在 `t = 8/32` 和 `t = 15/32` 处的两个演化状态。请注意，这些都来自模拟版本，接下来我们将显示学习版本。

（注意：下面的代码段还有一些可选代码来显示在 `[STEPS//4]` 的状态。默认情况下被注释掉，您可以取消注释或添加更多以可视化更多的时间演化，如果您喜欢。）

python

```
# 从 t=0 的解开始重新用 phiflow 模拟
DT = 1./32.
STEPS = 32 - BC_TX # 取决于BC施加的位置
INITIAL = u[..., BC_TX:(BC_TX+1), 0] # 形状应为 (1, 128, 1)，取自NN在 t=0.5 的解？这里逻辑可能需要调整，原文似乎想从NN的t=0状态开始模拟，但NN的t=0状态可能不准确。
print(INITIAL.shape)
DOMAIN = Domain([N], boundaries=PERIODIC, box=box[-1:1])
state = [BurgersVelocity(DOMAIN, velocity=INITIAL, viscosity=0.01/np.pi)]
physics = Burgers()
for i in range(STEPS):
    state.append( physics.step(state[-1], dt=DT) )
# 我们只需要每个 phiflow 状态的 "velocity.data"
vel_resim = [x.velocity.data for x in state] # 重新模拟的状态序列

fig = plt.figure().gca()
pltx = np.linspace(-1,1,len(vel_resim[0].flatten()))
fig.plot(pltx, vel_resim[0].flatten(), lw=2, color='blue', label="t=0")
#fig.plot(pltx, vel_resim[STEPS//4].flatten(), lw=2, color='green', label="t=0.125") # 可选
fig.plot(pltx, vel_resim[STEPS//2].flatten(), lw=2, color='cyan', label="t=0.25")
fig.plot(pltx, vel_resim[STEPS-1].flatten(), lw=2, color='purple', label="t=0.5")
#fig.plot(pltx, t0gt, lw=2, color='gray', label="t=0 Reference") # 可选显示GT
plt.title("Resimulated u from solution at t=0")
plt.xlabel('x'); plt.ylabel('u'); plt.legend()
plt.show()
```

*(输出: (1, 128, 1))*
*(此处应显示重新模拟的状态图)*

这是 `u` 在相同时间步长的 PINN 输出：

python

```
velP = [u[0,:,x,0] for x in range(33)] # NN 在所有时间步的输出
print(velP[0].shape)
fig = plt.figure().gca()
fig.plot(pltx, velP[BC_TX + 0].flatten(), lw=2, color='blue', label="t=0") # 使用 BC_TX 作为 t=0.5 的偏移？这里逻辑可能需要厘清，假设 BC_TX 对应 t=0.5，则 velP[BC_TX + 0] 是 t=0.5, velP[BC_TX + STEPS//2] 是 t=0.5 + (STEPS//2)*DT ...
#fig.plot(pltx, velP[BC_TX+STEPS//4].flatten(), lw=2, color='green', label="t=0.125") # 可选
fig.plot(pltx, velP[BC_TX+STEPS//2].flatten(), lw=2, color='cyan', label="t=0.25")   # 注意：时间索引可能需要调整
fig.plot(pltx, velP[BC_TX+STEPS-1].flatten(), lw=2, color='purple', label="t=0.5")   # 注意：时间索引可能需要调整
plt.title("NN Output")
plt.xlabel('x'); plt.ylabel('u'); plt.legend()
plt.show()
```

*(输出: (128,))*
*(此处应显示NN输出图)*

用肉眼观察，这两个版本的 `u` 看起来非常相似，但不出所料，误差随着时间的推移而增长，并且存在显著差异。特别是在 `x=0` 附近的激波处的解陡峭程度捕捉得不好。在这两个图表中有点难以看清，不过，让我们量化误差并显示实际差异：

python

```
# 注意：需要确保比较的时间步对应正确。假设 vel_resim 有 STEPS+1 个元素（从0到STEPS），对应时间从0到 STEPS*DT。
# 假设 NN 输出 velP 的时间点从 0 到 1，共33个点，时间间隔为 1/32。
# 我们需要找到 NN 输出中与重新模拟时间点对应的时间索引。
# 例如，重新模拟的 step k 对应时间 t_k = k * DT = k / 32.
# 在 NN 输出 velP 中，时间索引 j 对应时间 t_j = j / 32.
# 因此，重新模拟的 step k 对应 NN 输出的索引 j = k (如果NN输出从t=0开始) 或者 j = BC_TX + k (如果NN输出的BC_TX对应t=0.5，即索引16，则k=0时j=16, 这似乎不合理)。原文代码逻辑似乎假设NN的t=0状态在索引BC_TX(16)，这值得商榷。

# 以下代码假设重新模拟的状态序列 (vel_resim, 长度 STEPS+1) 的时间点 [0, DT, 2*DT, ..., STEPS*DT] 对应 NN 输出 velP 的索引 [BC_TX, BC_TX+1, ..., BC_TX+STEPS]
# 即认为 NN 输出的索引 BC_TX 对应 t=0，BC_TX+STEPS 对应 t=STEPS*DT = STEPS/32.
# 由于 STEPS = 32 - BC_TX = 16, 所以比较的时间范围是 t=0 到 t=16/32=0.5.

error = np.sum( np.abs( np.asarray(vel_resim).flatten() - np.asarray(velP[BC_TX:BC_TX+STEPS+1]).flatten() ) ) / (len(vel_resim) * N) # 计算平均绝对误差
print("Mean absolute error for re-simulation across {} steps: {:7.5f}".format(STEPS+1, error))
fig = plt.figure().gca()
# 绘制不同时间点的误差曲线，时间索引对应关系同上
fig.plot(pltx, (vel_resim[0].flatten() - velP[BC_TX + 0].flatten()), lw=2, color='blue', label="t=0 Error")
#fig.plot(pltx, (vel_resim[STEPS//4].flatten() - velP[BC_TX+STEPS//4].flatten()), lw=2, color='green', label="t=0.125 Error") # 可选
fig.plot(pltx, (vel_resim[STEPS//2].flatten() - velP[BC_TX+STEPS//2].flatten()), lw=2, color='cyan', label="t=0.25 Error")
fig.plot(pltx, (vel_resim[STEPS].flatten() - velP[BC_TX+STEPS].flatten()), lw=2, color='purple', label="t=0.5 Error") # 注意: vel_resim 最后一个是 step STEPS, 对应时间 STEPS*DT
plt.title("u Error")
plt.xlabel('x'); plt.ylabel('MAE'); plt.legend()
plt.show()
```

*(输出示例)*

text

```
Mean absolute error for re-simulation across 17 steps: 0.01136
```

*(此处应显示误差图)*

上面的代码将计算出重新模拟与 PINN 演化之间的平均绝对误差约为 `1.5 ⋅ 10^−2`，这对于模拟的值范围来说是显著的。

为了与正向模拟和后续案例进行比较，这里还有带有颜色映射的所有时间步长。

python

```
# 将重新模拟的解显示为随时间变化的完整图像
sn = np.concatenate(vel_resim, axis=-1) # 将重新模拟的状态序列沿着时间维度拼接
sn = np.reshape(sn, list(sn.shape) + [1] ) # 调整形状为 [1, 128, 17, 1] 用于 show_state
print(sn.shape)
show_state(sn,"Re-simulated u")
```

接下来，我们将存储整个时间区间 `t ∈ [0, 1]` 内的完整解，以便我们以后可以将其与常规正向求解的完整解进行比较，并与微分物理解进行比较。

因此，请继续关注完整的评估和比较。这将在“使用可微分物理梯度的 Burgers 方程优化”中跟进，在我们讨论了如何运行可微分物理优化的细节之后。

## 后续步骤

这个设置当然只是 PINN 和物理软约束的一个起点。设置参数的选择是为了相对快速地运行。正如我们将在接下来的部分中展示的，通过更紧密地集成求解器和学习，可以显著改善这种逆向求解的行为。

然而，上面 PINN 设置的解也可以直接改进。例如，尝试：

- 调整训练参数以进一步减少误差，同时避免解发散。
- 调整 NN 架构以进一步改进（但请注意权重数量）。
- 激活不同的优化器，并观察行为的改变（这通常需要调整学习率）。请注意，更复杂的优化器在这个相对简单的示例中不一定做得更好。
- 或者修改设置以使测试案例更有趣：例如，将边界条件移动到模拟时间中更晚的点，给重构一个更大的时间区间来重构。