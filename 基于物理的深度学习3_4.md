# 物理损失的讨论

到目前为止的好消息是——我们拥有一种深度学习方法，可以通过最小化残差的形式以软约束的方式纳入物理定律。然而，正如前面非常简单的例子所说明的那样，这带来了新的困难，并且仅仅是一个概念上的起点。

积极的一面是，我们可以利用具有反向传播功能的深度学习框架来计算模型的导数。同时，这也使得损失函数的形态（loss landscape）更加复杂，并且导数的可靠性依赖于学习到的表示（representation）。此外，每个导数计算都需要通过整个网络进行反向传播，这对于高阶导数来说可能非常昂贵。

虽然设置相对简单，但通常难以控制。神经网络具有自行优化解的灵活性，但与此同时，当它没有专注于解的正确区域时，就需要一些技巧来引导。

## 泛化能力？

需要注意的是，先前 PINN 优化的一个特点是，我们测试和约束解的位置就是我们最终感兴趣的位置。因此，从经典机器学习的角度来看，训练集、验证集和测试集之间没有真正的区别。为一组已知且给定的样本计算解更类似于经典优化，像之前 Burgers 方程例子这样的逆向问题就源于此。

对于机器学习，我们通常在一个假设下工作，即我们模型的最终性能将在一组不同的、可能未知的输入上进行评估。测试数据通常应该捕获这种分布外（Out Of Distribution, OOD）行为，以便我们可以估计我们的模型在部署到应用程序中将遇到的“真实世界”案例时的泛化能力。使用规定离散化的 v1 版本实际上具有此属性，并且可以泛化到新的输入。

相反，对于此处描述的 PINN 训练，我们是在一个已知且给定的时空区域内重构单个解。因此，来自该域的任何样本都遵循相同的分布，因此并不能真正代表测试样本或 OOD 样本。由于神经网络直接编码了解，我们也几乎不能期望它会在训练范围之外产生不同的解或表现良好。如果我们对不同的解感兴趣，我们必须从头开始训练神经网络。

---

## 总结

因此，物理软约束使我们能够利用神经网络的工具来编码 PDE 的解。随着它们更广泛的应用，我们将重点放在 PINNs（v2）上：一个固有的缺点是它们通常产生单一的解或非常狭窄的解流形（solution manifolds），并且它们不能很好地与传统数值技术结合。与**监督训练**中的**神经代理/算子**相比，我们在某种程度上倒退了一步。

例如，学习到的表示不适合使用经典的迭代求解器（如共轭梯度法）进行细化。这意味着过去几十年开发的许多强大技术无法在此上下文中使用。将这些数值方法重新引入画面将是接下来几节的中心目标之一。

### ✅ 优点：

*   使用物理模型
*   可以通过反向传播方便地计算导数

### ❌ 缺点：

*   收敛性有问题
*   物理约束仅作为软约束强制执行
*   与经典数值方法 largely incompatible (很大程度上不兼容)
*   导数的有用性依赖于学习到的表示

为了解决这些问题，我们接下来将研究如何通过使用**可微分求解器**来利用现有的数值方法来改进深度学习过程。